{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"CSC3206 Artificial Intelligence  This site hosts the lab sheets for:  CSC3206 Artificial Intelligence   School of Computing and Artificial Intelligence (SCAI), Faculty of Engineering and Technology (FET), Sunway University."},{"location":"#aim","title":"Aim","text":"<p>The aim of these labs is to guide the students to implement the basic artificial intelligence (AI) algorithms with and/or without Python libraries.</p>"},{"location":"#information","title":"Information","text":"<p>The labs are designed to follow the schedule of the lectures, therefore you will require the knowledge of the previous lectures to be able to conduct the lab.</p>"},{"location":"#schedule","title":"Schedule","text":"<p>The schedule is subject to change.</p> Week 1 Getting started Week 2 Lab 1: Python Refresher (MATLAB Onramp) Week 3 Lab 2: Python - Data Handling (Statistics Onramp) WEEK 5 Lab 3 (Part I): Search (Machine Learning Onramp) WEEK 6 Lab 3 (Part II): Search (Machine Learning Onramp) Week 8 The Quiz (Conducted during Lab Session) Week 9 Lab 4: Regression (Regression Methods with ML) Week 10 Lab 5: K Nearest Neighbours (Classification Methods with ML) Week 11 Lab 6: Decision Tree Week 12 Lab 7: Clustering (Cluster Analysis with ML) Week 14 Lab Test"},{"location":"get-start/","title":"Getting started","text":"<p>For the Lab and Practical work of CSC3206 Artificial Intelligence, we will be using Python as the programming language. The Anaconda distribution of Python is recommended, however, if you are familiar and comfortable with the vanilla distribution of Python. For those who have not installed Python in their machine, proceed to next session. This page only covers the installation of the Anaconda platform as, in our opinion, it is more beginner friendly in terms of installing packages and encapsulating environments.</p>"},{"location":"get-start/#installation","title":"Installation","text":"<ol> <li> <p>Download the Anaconda installer with Python 3 for your system from https://www.anaconda.com/download.</p> </li> <li> <p>Use the graphical installer to install Anaconda.</p> </li> </ol>"},{"location":"get-start/#launching-ide","title":"Launching IDE","text":"<p>You will be using the Spyder IDE for Python. Feel free to use other IDE or code editor with terminal if that's your preference.</p> <ol> <li> <p>Start the Anaconda Navigator from your application list.</p> </li> <li> <p>From Anaconda <code>base</code> environment, launch Spyder IDE.</p> </li> <li> <p>The Spyder IDE consists of three parts: the editor, the variable explorer, and the IPython Console.</p> </li> <li> <p>The editor is where you write your codes.</p> </li> <li> <p>The variable explorer shows the value of the variable after running the code.</p> </li> <li> <p>The IPython console allows you to execute commands, interact with the running code, and display visualisation.</p> </li> <li> <p>After the code is written in the editor, you can execute the code using F5 to run file.</p> </li> <li> <p>Then the variables and their values can be found in the variable explorer.</p> </li> </ol>"},{"location":"lab1/","title":"Lab 1 Python Refresher (MATLAB Onramp)","text":""},{"location":"lab1/#objective","title":"Objective","text":"<p>To understand basic syntax of Python programming language.</p>"},{"location":"lab1/#declare-a-variable","title":"Declare a variable","text":"<p>Python is strongly and dynamically typed.</p> <p>Strongly typed means the type of a variable does not change unexpectedly. When a variable is defined as a string with only numerical digits, it stays string, it doesn\u2019t become an integer or number.</p> <p>Dynamically typed means the type of a variable can change when a value of a different type is assigned to the variable.</p> <p>As Python is dynamically typed, we do not need to specify a type when we declare a variable. We just assign a value to the variable.</p> <ol> <li> <p>Define a variable named <code>val</code> and assign the value <code>'a'</code> to the variable.</p> <pre><code>val = 'a'\n</code></pre> <p>The type of the variable can be viewed in the variable explorer.</p> </li> <li> <p>Continue from the previous code block, assign the value <code>1</code> to the same variable. The variable will now be of type <code>int</code> instead of type <code>str</code>.</p> <pre><code>val = 1\n</code></pre> </li> </ol>"},{"location":"lab1/#array-manipulation","title":"Array manipulation","text":"<ol> <li> <p>Array in Python can be declared using a set of square brackets (<code>[...]</code>).</p> </li> <li> <p>To assign a variable with an empty array,</p> <pre><code>arr = []\n</code></pre> </li> <li> <p>To define an array with a series of numbers,</p> <pre><code>arr = [1,2,3,4,5]\n</code></pre> </li> <li> <p>To define an array with a series of alphabets,</p> <pre><code>arr = ['a','b','c','d','e']\n</code></pre> </li> <li> <p>An array can also be defined with values of mixed types.</p> <pre><code>arr = [1,'a',2,'b',3,'c']\n</code></pre> </li> <li> <p>Python arrays (or more commonly known as lists) are zero indexed arrays; it means to access the first element in the array <code>arr</code>,</p> <pre><code># in IPython console\narr[0] # gives the output of 1\narr[1] # gives the output of 'a'\n</code></pre> </li> <li> <p>Python arrays also support negative indexing; this means to get the last element in the array <code>arr</code>,</p> <pre><code># in IPython console\narr[-1] # gives the output of 'c'\n</code></pre> </li> <li> <p>Colon (<code>:</code>) can be used to extract multiple elements from an array. Maximum two (2) colons can be used for indexing/slicing an array. <code>arr[0:5:2]</code> The value before the first colon is the starting index, the value after the first colon is the ending index (exclusive), the value after the second colon is the number of steps. </p> <p>If the first value is empty, it is assumed as <code>0</code>.</p> <p>If the second value is empty, it is assumed as the length of the array, i.e. up till the last element in the array.</p> <p>If the third value is empty, it is assumed as <code>1</code>.</p> <pre><code># in IPython console\narr\n# [1, 'a', 2, 'b', 3, 'c']\narr[1:5]\n# ['a', 2, 'b', 3]\narr[1:5:2]\n# ['a', 'b']\narr[:3]\n# [1, 'a', 2]\narr[4:]\n# [3, 'c']\narr[2:-2]\n# [2, 'b']\narr[4:1]\n# []\narr[4:1:-1]\n# [3, 'b', 2] --&gt; slice in the reverse order\n</code></pre> </li> </ol>"},{"location":"lab1/#add-an-element-to-the-end-of-an-array","title":"Add an element to the end of an array","text":"<pre><code># in IPython console\narr.append(4)\narr\n# [1, 'a', 2, 'b', 3, 'c', 4]\n</code></pre>"},{"location":"lab1/#add-multiple-elements-to-the-end-of-an-array","title":"Add multiple elements to the end of an array","text":"<pre><code># in IPython console\narr.extend(['d',5,'e'])\narr\n# [1, 'a', 2, 'b', 3, 'c', 4, 'd', 5, 'e']\n</code></pre>"},{"location":"lab1/#assign-a-value-to-a-specific-index","title":"Assign a value to a specific index","text":"<pre><code># in IPython console\narr[0] = 0\narr\n# [0, 'a', 2, 'b', 3, 'c', 4, 'd', 5, 'e']\n</code></pre>"},{"location":"lab1/#insert-an-element-at-a-specific-index","title":"Insert an element at a specific index","text":"<pre><code># in IPython console\narr.insert(1,1)\narr\n# [0, 1, 'a', 2, 'b', 3, 'c', 4, 'd', 5, 'e']\n</code></pre>"},{"location":"lab1/#remove-an-element-at-a-specific-index","title":"Remove an element at a specific index","text":"<pre><code># in IPython console\ndel arr[0]\narr\n# [1, 'a', 2, 'b', 3, 'c', 4, 'd', 5, 'e']\n</code></pre>"},{"location":"lab1/#combining-arrays","title":"Combining arrays","text":"<p><code>zip</code> can be used to combine two or more arrays.</p> <pre><code># in editor\njoint_arr = list(zip([1,2,3], ['a','b','c']))\n</code></pre> <pre><code># in IPython console\njoint_arr\n# [(1,'a'),(2,'b'),(3,'c')]\n</code></pre>"},{"location":"lab1/#loops","title":"Loops","text":"<ol> <li> <p>Python supports <code>for</code> and <code>while</code> loops.</p> </li> <li> <p>To loop through every element in the array <code>arr</code> and print them to the console,</p> <pre><code>for a in arr:\n  print(a)\n# 1\n# a\n# 2\n# ...\n</code></pre> <p><code>for a in arr</code>: loops through all elements in <code>arr</code> and in each loop, an element in <code>arr</code> is assigned to the variable <code>a</code>.</p> </li> <li> <p>Note that in most other programming languages, code blocks are separated with delimiters such as the curly brackets (<code>{}</code>). This is not the case in Python. Code blocks in Python are defined by their indentation and normally initiated with a colon(<code>:</code>). </p> <p>For example,</p> <pre><code>for a in arr:\n  print(a)\nprint(arr)\n</code></pre> <p><code>print(a)</code> is the command to be executed in each loop.</p> <p><code>print(arr)</code> is only executed after the <code>for</code> loop is completed.</p> <pre><code>for a in arr:\n  print(a)\n  print(arr)\n</code></pre> <p>In this case, <code>print(arr)</code> is executed in each loop.</p> </li> <li> <p>Using <code>zip</code> we can loop through two arrays at once.</p> <pre><code>for item in zip(['a','b','c','d'],['artificial','breadth','cost','depth']):\n  print(item[0] + ' for ' + item[1])\n</code></pre> </li> <li> <p><code>enumerate</code> is useful in obtaining the index of the element in the array.</p> <pre><code>for (index, item) in enumerate(['a','b','c','d']):\n  print('Index of ' + item + ' is: ' + str(index))\n</code></pre> </li> <li> <p>Looping through a dictionary (<code>dict</code>) can also be done easily.</p> <pre><code>x_dict = {\n  'd': 'depth',\n  'e': 'estimation',\n  'f': 'frontier'\n}\nfor key,value in x_dict.items():\n  print(key + ' for ' + value)\n</code></pre> </li> <li> <p><code>while</code> loops can be defined similarly.</p> <pre><code>x = 0\nwhile x != 10: \n  x += 1\n  print(x)\nprint('while loop is completed')\n</code></pre> </li> <li> <p>The following example introduces nested array and multiple assignments.</p> <pre><code>arr = [['a',1],['b',2],['c',3],['d',4],['e',5],['f',6]]\nfor [a,n] in arr:\n  print(str(a) + ' is ' + str(n))\n</code></pre> </li> </ol>"},{"location":"lab1/#conditions","title":"Conditions","text":"<ol> <li> <p>The following operators can be used for conditional testing:</p> Operator Definition <code>==</code> Equivalence <code>!=</code> Inequivalence <code>&lt;</code> Less than <code>&lt;=</code> Less than or equal to <code>&gt;</code> Greater than <code>&gt;=</code> Greater than or equal to </li> <li> <p>Python also supports text operator for conditional testing:</p> Operator Definition Example (symbolic) Example (text) <code>is</code> Equivalence <code>a == 1</code> <code>a is 1</code> <code>not</code> Inequivalence <code>a != 1</code> <code>a is not 1</code>  or <code>not (a is 1)</code>  or <code>not a is 1</code>  or <code>not(a == 1)</code> </li> <li> <p>Combining two conditions can also be done with text operators <code>and</code> and <code>or</code>.</p> Symbolic operator Text operator <code>&amp;</code> <code>and</code> <code>|</code> <code>or</code> </li> </ol>"},{"location":"lab1/#user-defined-functions","title":"User-defined functions","text":"<ol> <li> <p>To define a custom function with the name of <code>custom_fcn</code>,</p> <pre><code>def custom_fcn():\n  print('This is a custom function to display custom message')\n</code></pre> </li> <li> <p>To call the function,</p> <pre><code>custom_fcn()\n# This is a custom function to display custom message\n</code></pre> </li> </ol>"},{"location":"lab1/#user-defined-functions-with-input-arguments","title":"User-defined functions with input arguments","text":"<ol> <li> <p>To define a custom function with input arguments,</p> <pre><code>def custom_fcn(msg):\n  print('This is a custom function to display ' + msg)\n</code></pre> </li> <li> <p>The function can be called by</p> <pre><code>custom_fcn('new message')\n# This is a custom function to display new message\n</code></pre> </li> </ol>"},{"location":"lab1/#user-defined-functions-with-optional-input-arguments","title":"User-defined functions with optional input arguments","text":"<ol> <li> <p>To define a custom function with optional input arguments, we just need to provide the default value to the optional input arguments.</p> <pre><code>def custom_fcn(msg = 'default message'):\n  print('This is a custom function to display ' + msg)\n</code></pre> </li> <li> <p>The input arguments can also be specified as named inputs.</p> <pre><code>custom_fcn(msg='new message')\n# This is a custom function to display new message\n</code></pre> </li> </ol>"},{"location":"lab1/#exercise","title":"Exercise","text":"<ol> <li> <p>Create a new file in Spyder. Define a variable named <code>friends</code> such that it is a nested array in which contains the name, home country, and home state/province of 10 of your friends (real or virtual). For example,</p> <pre><code>friends = [[\"James\", \"Malaysia\", \"Malacca\"], [\"Goh\", \"Australia\", \"Brisbane\"], [\"Don\", \"Malaysia\", \"Pahang\"]]\n</code></pre> </li> <li> <p>Create a function in the same file with three (3) optional input arguments, <code>name</code>, <code>home_country</code>, <code>home_state</code>.</p> <pre><code>def filterFriend(name=\"\", home_country=\"\", home_state=\"\"):\n  ...\n  return filtered\n</code></pre> <p>This function will filter <code>friends</code> based on the input arguments provided. The function will ignore the input argument if it has empty string, i.e. <code>\"\"</code>. If any of the input arguments is provided, the function will find the friends whose detail(s) matches the input.</p> <p>For example, </p> <p><code>filterFriend(name=\"James\")</code> will return <code>[[\"James\", \"Malaysia\", \"Malacca\"]]</code></p> <p><code>filterFriend(home_country=\"Malaysia\")</code> will return <code>[[\"James\", \"Malaysia\", \"Malacca\"], [\"Don\", \"Malaysia\", \"Pahang\"]]</code>.</p> </li> </ol>"},{"location":"lab1/#bonus-opportunity-matlab-onramp-certificate","title":"Bonus Opportunity: MATLAB Onramp Certificate","text":"<p>As part of enhancing your professional skills, you are encouraged to complete the MATLAB Onramp course provided by MathWorks.</p> <ul> <li>Estimated Time: ~2 hours</li> <li>Platform: Online (browser-based)</li> <li>Outcome: Digital Certificate of Completion from MathWorks</li> </ul> <p>Action Steps: 1. Access the course here: MATLAB Onramp - MathWorks Academy 2. Complete all activities and quizzes. 3. Download your Certificate of Completion. 4. Upload your certificate along with your Lab 1 submission on LMS.</p> <p>Bonus Recognition: - Students who complete and submit the certificate will receive a special recognition later in the semester (details to be explained in class). - This is entirely optional and will not affect your Lab 1 grade.</p>"},{"location":"lab2/","title":"Lab 2: Lab 2: Python - Data Handling (Statistics Onramp)","text":""},{"location":"lab2/#objective","title":"Objective","text":"<ol> <li>To learn the basic of the pandas Python library.</li> </ol>"},{"location":"lab2/#data-structures","title":"Data structures","text":"<p>In pandas, there are two types of data structures:</p> Structure Description Series 1D labeled homogeneously-typed array DataFrame General 2D labeled, size-mutable tabular structure with potentially heterogeneously-typed column"},{"location":"lab2/#instruction","title":"Instruction","text":"<p>For all sections in this lab other than the last section, use the IPython console (located normally at the right bottom corner) to run the codes.</p>"},{"location":"lab2/#imports","title":"Imports","text":"<ol> <li> <p>To import the <code>pandas</code> library,     <pre><code>import pandas as pd\n</code></pre></p> </li> <li> <p><code>NumPy</code> is a dependency of <code>pandas</code> and also a powerful Python library for scientific data processing. We may need to use <code>NumPy</code> from time to time. To import <code>Numpy</code>,     <pre><code>import numpy as np\n</code></pre></p> </li> <li> <p>It's common practice to import <code>pandas</code> as <code>pd</code> and <code>numpy</code> as <code>np</code>. You would see this a lot if you tried to search for tutorials or solutions online. However, it's just a convention, it is fine to use other names.</p> </li> </ol>"},{"location":"lab2/#series","title":"Series","text":"<ol> <li> <p>Creation </p> <ul> <li>from list,</li> </ul> <pre><code>s1 = pd.Series([1, 3, 5, np.nan, 6, 8])\ns2 = pd.Series([1, 3, 5, np.nan, 6, 8], index=[1, 2, 3, 4, 5, 'f'])\n</code></pre> <p>What is the difference between <code>s1</code> and <code>s2</code>?</p> <ul> <li>from dict,</li> </ul> <pre><code>d = {'a': 1, 'b': 2, 'c': 3}\ns3 = pd.Series(d)\n</code></pre> <ul> <li>from scalar value,</li> </ul> <pre><code>s4 = pd.Series(5, index=['a', 'b', 'c', 'd', 'e'])\n</code></pre> </li> <li> <p>Indexing of <code>Series</code></p> <ul> <li>try the following code to understand the getting and setting of a series with default indexing.</li> </ul> <pre><code>s = pd.Series(np.random.randn(5))\ns[0]\ns[0] = 1.5\ns\n</code></pre> <ul> <li>if the labels for the indices are specified,</li> </ul> <pre><code>s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])\ns['a']\ns[0]\ns['b'] = 1.8\ns\ns[2] = 2\ns\n</code></pre> </li> </ol>"},{"location":"lab2/#dataframe","title":"DataFrame","text":"<ol> <li> <p>Creation</p> <ul> <li>from NumPy array</li> </ul> <pre><code>df = pd.DataFrame(np.random.randn(6,4))\n</code></pre> <p>Indices and column names can be provided at creation.</p> <pre><code>df = pd.DataFrame(np.random.randn(6,4), index=list('abcdef'), columns=list('ABCD'))\n</code></pre> <ul> <li>from a dict</li> </ul> <p>run the following code and understand the functions used.</p> <pre><code>df2 = pd.DataFrame({\n  'A': 1,\n  'B': pd.Timestamp('20190930'),\n  'C': pd.date_range('20190930', periods=4),\n  'D': pd.Series(1, index=list(range(4)), dtype='float32'),\n  'E': np.array([3]*4, dtype='int32'),\n  'F': pd.Categorical(['test', 'train', 'test', 'train']),\n  'G': 'foo'\n})\n</code></pre> <p><code>dtypes</code> of a <code>DataFrame</code> can be viewed using <code>df2.dtypes</code>. In IPython, tab completion is enabled for column names and public attributes.</p> </li> <li> <p>Data display</p> <ul> <li> <p>What do <code>df.head(0)</code> and <code>df.tail()</code> do? What happens if I use <code>df.head(3)</code> and <code>df.tail(2)</code>?</p> </li> <li> <p><code>df.index</code> displays the indices of a data frame.</p> </li> <li> <p><code>df.columns</code> displays the columns of a data frame.</p> </li> <li> <p><code>df.describe()</code> shows a quick statistical summary of each column of the data.</p> </li> </ul> </li> <li> <p>Direct indexing</p> <ul> <li>to get a column,   <pre><code>df['A']\ndf.A\n</code></pre></li> </ul> <p><code>df[0]</code> would not work.</p> <ul> <li> <p>to select multiple columns,   <pre><code>df[['A', 'B']]\n</code></pre></p> </li> <li> <p>to get a slice of rows   <pre><code>df[0:4]\ndf['a':'d']\n</code></pre></p> </li> </ul> <p>Is the indexing inclusive or exclusive?</p> </li> <li> <p>Selection by label     With the following lines, identify how the function <code>.loc[...]</code> works</p> <pre><code>df.loc['a']\ndf.loc['a':'c']\ndf.loc[['a', 'c']]\ndf.loc[:, 'A']\ndf.loc[:, ['A', 'B']]\ndf.loc[:, 'A':'C']\ndf.loc['a':'c', ['A', 'B']]\ndf.loc[['a', 'c'], ['A', 'B']]\ndf.loc[['a', 'c'], 'A':'C']\ndf.loc['a':'c', 'A':'C']\ndf.loc['a', 'A']\ndf.loc['a', 'A':'C']\n</code></pre> <p><code>df.at['a','A']</code> is equivalent to <code>df.loc['a','A']</code> (only to get a scalar value)</p> <p>The object returned by a <code>.loc</code> is either a series (1-D), data frame (2-D), or scalar (single value).</p> </li> <li> <p>Selection by position     <code>.iloc</code> and <code>.iat</code> work similarly as <code>.loc</code> and <code>.at</code>. The only difference is that, instead of the label of the row/column, we will use the position of the row/column.</p> <p>Find the equivalent usage of <code>.iloc</code> that provides the same outputs as the previous lines for <code>.loc</code>.</p> </li> <li> <p>Boolean indexing     Investigate the differences in the outputs of the following lines:     <pre><code>df[df.A &gt; 0]\ndf[df &gt; 0]\n</code></pre></p> <p>Filtering of a column can be done with <code>.isin</code>. <pre><code>df2 = df.copy()\ndf2['E'] = ['one', 'one', 'two', 'three', 'four', 'three']\ndf2[df2['E'].isin(['two', 'four'])]\n</code></pre></p> </li> </ol>"},{"location":"lab2/#data-manipulation","title":"Data manipulation","text":"<p><code>pandas</code> library provides a lot of functions to manipulate data.</p> <p>Go to UCI datasets to download <code>iris.data</code> and <code>iris.names</code> from the <code>Data Folder</code>.</p> <ol> <li> <p>Load <code>iris.data</code> as a data frame (Hint: <code>iris.data</code> is a CSV file)</p> </li> <li> <p>Update the column names based on <code>iris.names</code>.</p> </li> <li> <p>Calculate the mean, min, max, and standard deviation of each column.</p> </li> <li> <p>Create a new column called <code>class value</code> using the following code:     <pre><code>df['class value'] = pd.factorize(df['class'])[0]\n</code></pre>     Investigate the output of <code>pd.factorize</code>.</p> </li> <li> <p>Group the data according to the class. (Hint: <code>.groupby</code>)</p> </li> <li> <p>Identify the function to extract each group using the name of the class.</p> </li> <li> <p>Calculate the mean, min, max, and standard deviation of each column in each group.</p> </li> <li> <p>Produce a scatter plot for any two columns using <code>matplotlib</code> library.</p> </li> <li> <p>Identify the methods (at least 2) to loop through a data frame row by row.</p> </li> </ol>"},{"location":"lab2/#bonus-opportunity-statistics-onramp-certificate","title":"Bonus Opportunity: Statistics Onramp Certificate","text":"<p>To strengthen your data analysis foundations, you are encouraged to complete the Statistics Onramp course provided by MathWorks.</p> <ul> <li>Estimated Time: ~2 hours  </li> <li>Platform: Online (browser-based)  </li> <li>Outcome: Digital Certificate of Completion from MathWorks</li> </ul> <p>Action Steps: 1. Access the course here: Statistics Onramp \u2013 MathWorks Academy 2. Complete all lessons and interactive exercises. 3. Download your Certificate of Completion. 4. Upload your certificate together with your Lab X submission on LMS.</p> <p>Bonus Recognition: - Students who complete and submit the certificate will receive bonus recognition later in the semester. - This task is optional and does not affect your Lab X grade.</p>"},{"location":"lab3a/","title":"Lab 3 (Part I): Search Algorithms (Machine Learning Onramp)","text":""},{"location":"lab3a/#breadth-first-search-bfs-algorithm","title":"Breadth-First Search (BFS) algorithm","text":"<p>After completing this lab, you will be able to implement the Breadth-First Search (BFS) search algorithm in Python.</p> <p>The first search problem we are focusing on is Nick\u2019s route-finding problem in Romania, starting in Arad to reach Bucharest. The road map of Romania, which is the state space of the problem is given as follows:</p> 75 71 151 140 118 111 70 75 120 146 80 99 97 138 101 211 90 85 98 86 142 92 87 Arad Zerind Oradea Sibiu Fagaras Rimnicu Vilcea Pitesti Craiova Drobeta Mehadia Lugoj Timisoara Bucharest Giurgiu Urziceni Hirsova Eforie Vaslui Iasi Neamt"},{"location":"lab3a/#elements-of-search-algorithm","title":"Elements of Search Algorithm","text":"<p>As we discussed in the class, in order to execute a Search Algorithm, we need to define the following items: </p> <ul> <li>State Representation </li> <li>The State Space </li> <li>The Transition Model </li> </ul> <p>Furthermore, you will need your program to be more robust to be able to implement other Search Algorithms without drastic changes. More on that later. </p>"},{"location":"lab3a/#1-state-representation","title":"1. State Representation","text":"<p>In this problem, the only state we need to consider is the location of Nick. Therefore we can use the names of the cities as the state.</p> <p>Since Nick is starting in Arad, going to Bucharest, we can define the initial state and goal state as: </p> <pre><code>initial_state = \"Arad\"\ngoal_state = \"Bucharest\"\n</code></pre>"},{"location":"lab3a/#2-the-state-space","title":"2. The State space","text":"<p>The transition model provides the way to identify the child of a node in a search tree given a specific action. In this problem, we need to translate the whole state space from the geographical network into the program together with the step costs between the connected states.</p> <p>The important information from the state space is the connections between states and the step costs between connected states. Notice that in this problem the connections are reversible. Therefore in our state space the connection from Arad to Zerind and the connection from Zerind to Arad are identical, hence only one instance of that connection is needed.</p> <p>The most straightforward way of defining the state space is by using a nested array, in which each inner array consists of the two connected states and its cost. </p> <p>Define a variable <code>state_space</code> to store the state space. As seen below, it is a nested list (a list containing inner lists). The following code shows the first three elements in the nested list.  <pre><code>state_space = [\n  ['Arad', 'Zerind', 75],\n  ['Arad', 'Timisoara', 118],\n  ['Timisoara', 'Lugoj', 111],\n  ...\n]\n</code></pre></p> <p>Task 1: Complete the list of cities and distances in the <code>state_space</code> variable </p>"},{"location":"lab3a/#3-the-transition-model","title":"3. The Transition model","text":"<p>In this problem, the transition model is defined by the action of traveling between connected cities. To represent this action, we can create a function that searches through the state space to find the children of the current node, which effectively represents the available travel options.</p> <p>This function iterates through the <code>state_space</code> variable, checking for connections linked to the current node. Each city connected to the current node becomes a child of that node. We define a new function called <code>expandAndReturnChildren</code> to handle this process.</p> <pre><code>def expandAndReturnChildren(state_space, node):\n  children = []\n  for [n,m,c] in state_space:\n    if n == node:\n      children.append(m)\n    elif m == node:\n      children.append(n)\n  return children\n</code></pre> <p>This function explores the state_space, and returns a list of all possible children of <code>node</code>.</p> <p>Discussion:  - how does this function actually work? read the code and see if you can understand its inner workings. - Instead of n,m,c, why not use something more descriptive like City1, City2, Cost ?  </p> <p>Task 2: Implement <code>expandAndReturnChildren</code> in your program and test its validity</p>"},{"location":"lab3a/#using-python-classes-objects-object-oriented-programming","title":"Using Python Classes &amp; Objects (Object Oriented Programming)","text":"<p>Although we can proceed with the current code to implement BFS, it will become increasingly complex as the search deepens. To make the code more manageable and adaptable for future search algorithms, we can adopt an object-oriented approach. By defining a class to represent each \"city\" in the state space tree and using objects to model each city instance, we simplify the structure. This not only enhances readability but also makes the code more robust and flexible for implementing other search strategies.</p> <p>To achieve this, we define each city as a Node. Each node stores key information, - state: the name of the city itself - parent: the name of the preceding city in the search tree.  - children: a list cites in the branches in the search tree. </p> <p>The Class definition also includes a method that adds children cities to the current node (more on that later)</p> <pre><code>class Node:\n  def __init__(self, state=None, parent=None):\n    self.state = state\n    self.parent = parent\n    self.children = []      \n\n  def addChildren(self, children):\n    self.children.extend(children)      \n</code></pre> <p>This structure allows us to trace the path from any node back to the initial state, enabling efficient path reconstruction once the goal is found.</p> <p>Class in Python</p> <p>In Python, to define a class, the class needs to have the function <code>__init__</code> with at least one input <code>self</code>. This function is called when an object is initiated with this class. The internal variable <code>self</code> defines the properties of the object. The input arguments apart from <code>self</code> for the function <code>__init__</code> are the parameters to be passed when initiating a new object.</p> <p>In a class, additional functions can also be defined, and these will be the methods for the object of this class. </p> <p>With this implementation of node as a class, the <code>expandAndReturnChildren</code> function is updated to be</p> <pre><code>def expandAndReturnChildren(state_space, node):\n  children = []\n  for [n,m,c] in state_space:\n    if n == node.state:\n      childnode = Node(m, node)\n      children.append(childnode)\n    elif m == node.state:\n      childnode = Node(n, node)\n      children.append(childnode)\n  return children\n</code></pre> <p>Discussion: </p> <ul> <li>Discuss the changes to <code>expandAndReturnChildren</code> (Specfically: Objects vs. Strings) </li> <li>in this function, we first create a <code>childenode</code> object, then in the next line we append it to <code>Children</code>, why not do that in one line? </li> <li>what about the cost? we seem to ignore so far, why?. can you modify the function to capture the cost as well? (more on that later)  </li> </ul> <p>Think about these issues before you continue. </p> <p>A Quick check</p> <p>Your current code should look like</p> <pre><code>initial_state = \"Arad\"\ngoal_state = \"Bucharest\"\n\nstate_space = [\n  ['Arad', 'Zerind', 75],\n  ['Arad', 'Timisoara', 118],\n  ['Timisoara', 'Lugoj', 111],\n  ...\n]\n\nclass Node:\n  def __init__(self, state=None, parent=None):\n    self.state = state\n    self.parent = parent\n    self.children = []      \n\n  def addChildren(self, children):\n    self.children.extend(children)              \n\ndef expandAndReturnChildren(state_space, node):\n  children = []\n  for [n,m,c] in state_space:\n    if n == node.state:\n      childnode = Node(m, node)\n      children.append(childnode)\n    elif m == node.state:\n      childnode = Node(n, node)\n      children.append(childnode)\n  return children\n</code></pre> <p>Separation of Problem Definition vs. Algorithm Definition.</p> <p>By defining the key elements\u2014namely, the initial state, goal state, state space, and transition model\u2014before implementing the BFS algorithm, we have effectively separated the problem from the algorithm.</p> <p>This separation offers significant advantages in programming, particularly in terms of flexibility and reusability:</p> <ul> <li> <p>The initial state represents the starting point of the search\u2014in this case, the city where the journey begins.</p> </li> <li> <p>The goal state defines the destination or target that the algorithm is trying to reach.</p> </li> <li> <p>The state space outlines all the possible connections between cities, including the cost of traveling from one to another. It serves as the map or environment within which the search operates.</p> </li> <li> <p>The transition model defines how one can move from one state (city) to another. It governs the valid moves or actions available and is typically implemented as a function that returns the next possible states (children) from a given current state.</p> </li> </ul>"},{"location":"lab3a/#the-breadth-first-search-bfs-algorithm","title":"The Breadth-First Search (BFS) algorithm","text":"<p>Below is the complete code for the BFS Search Algorithm. Please review it first \u2014 we\u2019ll then go through it step by step to understand how it works</p> <p>The BFS Algorithm: The Complete Code</p> <pre><code># The BFS Search Algorithm  \ndef bfs(state_space, initial_state, goal_state):\n    # STEP 1 - Initialization\n    frontier    = []        # the front-line, the CURRENT exploration/test node\n    explored    = []        # list of nodes we already explored  \n    found_goal  = False\n    frontier.append(Node(initial_state, None))  # first node in the frontier is the initial_state       \n    goal_node   = Node()\n    solution    = []    \n    path_cost = 0\n\n    # STEP 2 - Search for Goal Loop  \n    while not found_goal:\n\n        # 2.1 Manage the Frontier &amp; Explored Lists \n        children = expandAndReturnChildren(state_space, frontier[0])\n        frontier[0].addChildren(children)\n        explored.append(frontier[0])\n        del frontier[0]\n\n        # 2.2 Goal Test\n        for child in children:\n            # first, check if node was alrady expanded or explored\n            if not (child.state in [e.state for e in explored]) and not (child.state in [f.state for f in frontier]): \n                # next, check if node is goal\n                if child.state == goal_state:\n                    found_goal = True       # end algorithm \n                    print(\"Goal Found!\")\n                    goal_node = child       # for later processing\n                frontier.append(child)      # to search deeper   \n\n        # 2.3 Progress output  \n        print(\"Explored:\", [e.state for e in explored])\n        print(\"Frontier:\", [f.state for f in frontier])\n        print(\"Children:\", [c.state for c in children])\n        print(\"\")\n\n    # STEP 3 Find Solution path \n    solution = [goal_node.state]        # start from goal node\n    trace_node = goal_node              # use the trace node to trace the path back to the initial node\n\n    # 3.1 trace your steps and find the solution path\n    while trace_node.parent is not None:                # are you back to the initial_state ?\n        solution.insert(0, trace_node.parent.state)     # then find the parent and add it to the solution list\n        trace_node = trace_node.parent                  # set trace to parent (to go back one level, and repeat)\n\n    # 3.2 determine the cose of the solution path. \n    for i in range(len(solution) - 1):\n        city1 = solution[i]\n        city2 = solution[i + 1]\n\n        for [from_city, to_city, cost] in state_space:\n            if (from_city == city1 and to_city == city2) or (from_city == city2 and to_city == city1):\n                path_cost += cost\n                break  # Exit once the matching pair is found\n\n    return solution, path_cost\n</code></pre> <p>Now, let's go step by step. As discussed in the class, the BFS algorithm revolves around the use of two key lists:</p> <ul> <li> <p>frontier: Nodes (cities) that are discovered but not yet explored</p> </li> <li> <p>explored: Nodes (cities) that have been fully examined</p> </li> </ul> <p>The algorithm systematically moves nodes from the frontier to explored as it traverses the <code>state_space</code>, continuing until the <code>goal_state</code> is found. The major steps of the BFS algorithm include the following key steps:</p> <ul> <li> <p><code>Initialization:</code> Set up the initial variables, including placing the starting city into the frontier.</p> </li> <li> <p><code>The Search Loop:</code> This step repeatedly explores the search space by expanding nodes, testing for the goal, and updating progress.</p> </li> <li> <p><code>Solution &amp; Cost:</code> Once the goal is found, this step traces the solution path back to <code>inital_stat</code>, then calculates the its cost. </p> </li> </ul> <p>Step 0: Function definition and inputs</p> <p>We will now implement the BFS algorithm as a Python function that takes the <code>state_space</code>, <code>initial_state</code>, and <code>goal_state</code> as arguments (inputs). </p> <p>Additionally, the BFS funtion utilizes the <code>expandAndReturnChildren</code> function and the <code>Node</code> Class defintion and its methods.</p> <pre><code>def bfs(state_space, initial_state, goal_state):\n</code></pre> <p>Step 1: Initialization</p> <pre><code>def bfs(state_space, initial_state, goal_state):\n\n    # STEP 1 - Initialization\n    frontier    = []        \n    explored    = []         \n    found_goal  = False\n\n    frontier.append(Node(initial_state, None))  \n    goal_node   = Node()\n    solution    = []    \n    path_cost = 0\n</code></pre> <p>In this first step, we set up the key variables that drive the BFS process\u2014defining the <code>frontier</code>, <code>explored</code>, and placing the initial state as the starting node. While some variables like <code>goal_node</code>, <code>solution</code>, and <code>path_cost</code> are prepared for later use. </p> <p>Discussion:  - evaluate each variable definition and explain why it is needed - why is goal_node is defined as a blank object and not a String? </p> <p><code>Node(initial_state, None)</code></p> <p>As the root node has no parent, we use <code>None</code> as the value of the parent of root node.</p> <p>Step 2: The Search Loop</p> <p>After initialization, the algorithm enters the search loop, which is the heart of BFS. In this loop, we systematically explore the nodes in the <code>frontier</code> until the goal is found. Each cycle of the loop involves three main parts:</p> <ul> <li>2.1 Managing the <code>frontier</code> and <code>explored</code> lists to track which nodes have been discovered and processed,</li> <li>2.2 Performing a goal test to check whether we\u2019ve reached the destination, and</li> <li>2.3 Outputting the current progress to help us observe how the search unfolds step by step.</li> </ul> <p>We\u2019ll now break down each of these subsection in more detail</p> <pre><code>    # STEP 2 - The Search Loop  \n    while not found_goal:\n        # 2.1 Manage the Frontier &amp; Explored Lists \n        children = expandAndReturnChildren(state_space, frontier[0])\n        frontier[0].addChildren(children)\n        explored.append(frontier[0])\n        del frontier[0]\n</code></pre> <p>Discussion:  - read each line and understand what is going on </p> <pre><code>        # 2.2 Goal Test\n        for child in children:\n            # first, check if node was alrady expanded or explored\n            if not (child.state in [e.state for e in explored]) and not (child.state in [f.state for f in frontier]): \n                # next, check if node is goal\n                if child.state == goal_state:\n                    found_goal = True       # end algorithm \n                    print(\"Goal Found!\")\n                    goal_node = child       # for later processing\n                frontier.append(child)      # to search deeper   \n</code></pre> <p>Discussion:  - what happens if we dont check for redundancies?</p> <p>List comprehension</p> <p>In step 2.2, we use a special Syntax; <code>[e.state for e in explored]</code> which is referred to as List Comprehension. List comprehension provides a shorter syntax to create a new list. </p> <p>This example loops through the list variable <code>explored</code> and create a list with the values of <code>.state</code> for each element (node) in the <code>explored</code> list.</p> <p>This one-liner is equivalent to</p> <pre><code>explored_nodes = []\nfor e in explored:\n  explored_nodes.append(e.state)\n</code></pre> <pre><code>        # 2.3 Progress output  \n        print(\"Explored:\", [e.state for e in explored])\n        print(\"Frontier:\", [f.state for f in frontier])\n        print(\"Children:\", [c.state for c in children])\n        print(\"\")\n</code></pre> <p>Discussion:  - Is this step really necessary? what value does it add to your code? </p> <p>Step 3: Solution &amp; Cost</p> <p>Now that the algorithm has identified the <code>goal_node</code>, we can trace the solution through the parent of the goal node all the way back to the root node (node with no parent). Then the function should return the solution of BFS.</p> <pre><code>    # STEP 3 Find Solution path \n    solution = [goal_node.state]        \n    trace_node = goal_node              \n\n    # 3.1 trace your steps and find the solution path\n    while trace_node.parent is not None:                \n        solution.insert(0, trace_node.parent.state)     \n        trace_node = trace_node.parent                  \n</code></pre> <p>Discussion:  - Read the code of each step and understand its inner workings  - try to understand how the solution path is created in the end - Question: what is the difference between the Solution List, and the other lists we defined earlier (such as Frontier or Explored)? </p> <p>Next, the final step, is the determine the cost of this solution path. At this point, we finally utilize the cost element that is part of the <code>state_space</code> as we discussed early on. </p> <pre><code>    # 3.2 determine the cose of the solution path. \n    for i in range(len(solution) - 1):\n        city1 = solution[i]\n        city2 = solution[i + 1]\n\n        for [from_city, to_city, cost] in state_space:\n            if (from_city == city1 and to_city == city2) or (from_city == city2 and to_city == city1):\n                path_cost += cost\n                break   \n</code></pre> <p>Discussion:  - Read the code of each step and understand its inner workings  - what is += and why is it used here ?  - In your opinion, is this an efficient way to calculate path cost? is there a better way?</p>"},{"location":"lab3a/#running-the-algorithm","title":"Running the algorithm","text":"<p>Now we have two functions <code>expandAndReturnChildren</code> and <code>bfs</code>, alongside with the variables <code>state_space</code>, <code>initial_state</code>, and <code>goal_state</code>.</p> <p>To run a script to execute the <code>bfs</code> function, we can have the script file structured as such:</p> <pre><code>    initial_state = 'Arad'\n    goal_state = 'Bucharest'\n\n    state_space = [\n      ...\n    ]\n\n    class Node:\n      ...\n\n    def expandAndReturnChildren(...):\n      ...\n\n    def bfs(...):\n      ...\n\n    print('Solution: ' + str(bfs(state_space, initial_state, goal_state)))\n</code></pre> <p>Discussion:  - what if we want to run this code to test two other cities ?  - for example, what if Nick was in Oradea and wanted to go to Vaslui - how would you modify the code (without redefining inital and goal we set above) to do that? </p> <p>Task 3: Run and test your BFS Search Algorithm</p>"},{"location":"lab3a/#preparation-for-next-week-part-ii","title":"Preparation for next week (Part II)","text":"<p>Reusing code is one of the most valuable skills a programmer can develop.</p> <p>A great way to reuse the code for other search algorithms is to encapsulate it into a library or module, which you can then import and call in future Python programs.</p> <p>In fact, any <code>.py</code> file can be used to define a Python library or module. However, to prevent code outside the functions from executing when the file is imported as a library (instead of being run as a script), we can add an extra condition check.</p> <pre><code>class Node:\n  ...\n\ndef expandAndReturnChildren(...):\n  ...\n\ndef bfs(...):\n  ...\n\nif __name__ == '__main__':\n  state_space = [\n  ...\n  ]\n\n  initial_state = 'Arad'\n  goal_state = 'Bucharest'\n\n  print('Solution: ' + str(bfs(state_space, initial_state, goal_state)))\n</code></pre> <p><code>__name__</code> is a special variable in Python that evaluates to the name of the current module. This variable has the value of <code>'__main__'</code> if it's called as the main program rather than a module or library.</p> <p>This part is essentially the <code>main</code> function in other programming languages like C++ and Java.</p> <p>Execute the script and resolve any error.</p> <p>Prep work for Part II</p> <ol> <li> <p>Fully understand the code as you will have to modify the code for other problem/search algorithms in future labs.</p> </li> <li> <p>How would you modify the code to run other uninformed search algorithms such as uniform-cost search, depth-first search, etc.? Which part(s) of the code do you need to modify? Think about it before you work on that in next part of this lab</p> </li> </ol>"},{"location":"lab3a/#bonus-opportunity-machine-learning-onramp-certificate","title":"Bonus Opportunity: Machine Learning Onramp Certificate","text":"<p>To complement your learning in this lab and explore applied machine learning techniques, you are encouraged to complete the Machine Learning Onramp course by MathWorks.</p> <ul> <li>Estimated Time: ~2 hours  </li> <li>Platform: Online (browser-based)  </li> <li>Outcome: Digital Certificate of Completion from MathWorks</li> </ul> <p>Action Steps: 1. Access the course here: Machine Learning Onramp \u2013 MathWorks Academy 2. Go through all the lessons and complete the interactive activities. 3. Download your Certificate of Completion. 4. Upload your certificate along with your Lab X submission on LMS.</p> <p>Bonus Recognition: - Students who complete and submit this certificate will be acknowledged later in the semester. - This is optional and will not impact your Lab X grade.</p>"},{"location":"lab3b/","title":"Lab 3 (Part II): Search Algorithms (Machine Learning Onramp)","text":""},{"location":"lab3b/#part-ii-uniform-cost-search-ucs-algorithm","title":"PART II - Uniform-Cost Search (UCS) Algorithm","text":""},{"location":"lab3b/#objective","title":"Objective","text":"<p>To create Python script to execute Uniform Cost Search (UCS) algorithm.</p>"},{"location":"lab3b/#problem-to-be-solved","title":"Problem to be solved","text":"<p>We will revisit Nick\u2019s route-finding problem in Romania, starting in Arad to reach Bucharest, and implement uniform-cost search to solve the problem.</p> 75 71 151 140 118 111 70 75 120 146 80 99 97 138 101 211 90 85 98 86 142 92 87 Arad Zerind Oradea Sibiu Fagaras Rimnicu Vilcea Pitesti Craiova Drobeta Mehadia Lugoj Timisoara Bucharest Giurgiu Urziceni Hirsova Eforie Vaslui Iasi Neamt"},{"location":"lab3b/#continue-work-from-part-i","title":"Continue work from Part I","text":"<p>Uniform Cost Search (UCS) changes the sorting of the frontier by ordering it with its path cost up to the leaf node and expanding the leaf node with the lowest cost.</p> <ol> <li> <p>Upcate the code from Part I to be able to sort the frontier following the path cost up to the leaf node.</p> </li> <li> <p>If a latter-found node has the same state as a previous node and the previous node has been expanded, what should be done?</p> </li> <li> <p>What happens when a latter-found node has the same state as a previous node and have a shorter path cost? How do we implement this in our code?</p> </li> <li> <p>Note also, the goal test should be applied during expansion, not generation.</p> </li> </ol> <p>Execute the program and investigate if the program is working correctly.</p>"},{"location":"lab3b/#1-the-updated-node-class-definition","title":"1. The updated Node Class definition","text":"<pre><code>class Node:\n  def __init__(self, state=None, parent=None, cost=0):\n    self.state = state\n    self.parent = parent\n    self.children = []\n    self.cost = cost    \n\n  def addChildren(self, children):\n    self.children.extend(children)\n</code></pre> <p>Discussion: take a note of how the cost is now part of the node definition</p>"},{"location":"lab3b/#2-the-updated-expandandreturnchildren-function","title":"2. The updated ExpandAndReturnChildren function","text":"<pre><code>def expandAndReturnChildren(state_space, node):\n  children = []\n  for [m,n,c] in state_space:\n    # if a match is found, add the other as a child &amp; accumulate costs\n    if m == node.state:\n      children.append(Node(n, node.state, node.cost+c)) \n    elif n == node.state:\n      children.append(Node(m, node.state, node.cost+c))\n  return children\n</code></pre> <p>Discussion: What is the difference between cost and c ? </p>"},{"location":"lab3b/#3-the-appendandsort-frontier-function-new","title":"3. The AppendAndSort (Frontier) function (new)","text":"<pre><code>def appendAndSort(frontier, node):\n  duplicated = False\n  removed = False\n  for i, f in enumerate(frontier):\n    if f.state == node.state:\n      duplicated = True\n      if f.cost &gt; node.cost:\n        del frontier[i]\n        removed = True\n        break    \n  if (not duplicated) or removed:\n    insert_index = len(frontier)\n    for i, f in enumerate(frontier):\n      if f.cost &gt; node.cost:\n        insert_index = i\n        break\n    frontier.insert(insert_index, node)\n  return frontier\n</code></pre> <p>Discussion: similarly to how we did it in BFS, run through the loops and evaluate this function</p>"},{"location":"lab3b/#4-the-ucs-algorithm-incomplete","title":"4. The UCS Algorithm (incomplete)","text":"<pre><code># The UCS Algorithm \ndef ucs(state_space, initial_state, goal_state):\n\n  # Step 1 - Initiate variables &amp; conditions\n\n  # Step 2 - Search Loops \n  while not found_goal:\n\n    # 2.1 goal test \n\n    # 2.2 Manage the Frontier &amp; Explored Lists \n\n    # 2.3 Progress Update\n\n\n  # Step 3 Solution &amp; Cost   \n\n  return solution, path_cost\n</code></pre> <p>Discussion: Complete &amp; run this based on the work we did in BFS &amp; definitions above</p>"},{"location":"lab3b/#5-all-together-now","title":"5. All together now","text":"<p>Your complete Program show now look like this</p> <pre><code>class Node:\n  ...\n\ndef expandAndReturnChildren(...):\n  ...\n\ndef appendAndSort(...):\n  ...\n\ndef ucs(...):\n  ...\n\nif __name__ == '__main__':\n  state_space = [\n  ...\n  ]\n\n  initial_state = 'Arad'\n  goal_state = 'Bucharest'\n\n  print('Solution: ' + str(ucs(state_space, initial_state, goal_state)))\n</code></pre>"},{"location":"lab3b/#bonus-opportunity-machine-learning-onramp-certificate","title":"Bonus Opportunity: Machine Learning Onramp Certificate","text":"<p>To complement your learning in this lab and explore applied machine learning techniques, you are encouraged to complete the Machine Learning Onramp course by MathWorks.</p> <ul> <li>Estimated Time: ~2 hours  </li> <li>Platform: Online (browser-based)  </li> <li>Outcome: Digital Certificate of Completion from MathWorks</li> </ul> <p>Action Steps: 1. Access the course here: Machine Learning Onramp \u2013 MathWorks Academy 2. Go through all the lessons and complete the interactive activities. 3. Download your Certificate of Completion. 4. Upload your certificate along with your Lab X submission on LMS.</p> <p>Bonus Recognition: - Students who complete and submit this certificate will be acknowledged later in the semester. - This is optional and will not impact your Lab X grade.</p>"},{"location":"lab4/","title":"Lab 4: Linear Regression (Regression Methods with ML)","text":""},{"location":"lab4/#objectives","title":"Objectives","text":"<ol> <li> <p>To develop the script to perform gradient descent on linear regression model with least squares method using Python.</p> </li> <li> <p>To train a linear regression model with least squares method using the <code>scikit-learn</code> Python library.</p> </li> </ol>"},{"location":"lab4/#dataset","title":"Dataset","text":"<p>Throughout this lab we will be using the data for 442 diabetes patients. The data can be import from the <code>sklearn</code> library.</p> <pre><code>from sklearn import datasets\ndiabetes = datasets.load_diabetes()\n</code></pre> <p><code>diabetes</code> contains the keys of <code>data</code>, <code>target</code>, <code>DESCR</code>, <code>feature_names</code>, <code>data_filename</code>, and <code>target_filename</code>. The description of the diabetes dataset is given by</p> <pre><code>print(diabetes.DESCR)\n</code></pre> <p>Task: What are the keys for the input data and the output/target data?</p>"},{"location":"lab4/#gradient-descent-on-linear-regression-model-with-least-squares-method","title":"Gradient descent on linear regression model with least squares method","text":"<ol> <li> <p>Load the dataset as described in the Dataset Section.</p> <pre><code>from sklearn import datasets\ndiabetes = datasets.load_diabetes()\n</code></pre> </li> <li> <p>Convert the dataset into a pandas DataFrame.</p> <pre><code>import pandas as pd\ndt = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\ny = pd.DataFrame(diabetes.target, columns=['target'])\n</code></pre> </li> <li> <p>In machine learning, the common practice is to split the dataset into training data and testing data (some also include the validation data). The testing data is not used during the training phase, but only after training to evaluate the model.</p> <p>The split is normally done such that the training data has a larger portion than the testing data. In this case, let's use a 80-20 split for the training data and testing data.</p> <p><code>sklearn</code> provides a function to split the train-test data given a percentage.</p> <pre><code>from sklearn.model_selection import train_test_split\n</code></pre> <p>Task: How do you use <code>train_test_split</code> to split the data and target into 80-20 proportion? (Define the training features as <code>X_train</code>, training target as <code>y_train</code>, testing features as <code>X_test</code>, testing target as <code>y_test</code>.)</p> </li> <li> <p>Before we train the data, a few functions need to be defined. We will start with defining the model of a simple regression line, i.e. \\(y = mx + c\\). Define the function name as <code>model</code> with 3 inputs <code>x</code>, <code>m</code>, and <code>c</code>. The function should return the value of <code>y</code>.</p> </li> <li> <p>The next function to define is the cost function, i.e. </p> \\[J = \\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\\] <p>Name the function as <code>cost</code> with 2 inputs <code>y</code> as the array of target values and <code>yh</code> as the array of predicted target values. The function returns a scalar value of the cost. Assume the arrays are pandas Series.</p> </li> <li> <p>We also need to define the function to calculate the derivatives of the cost with respect to each parameter. Name the function as <code>derivatives</code> with 3 inputs <code>x</code> as the array of input values, <code>y</code> as the array of of target values, and <code>yh</code> as the array of predicted target values. The function returns a dict object with keys <code>m</code> to hold the value of \\(\\frac{\\partial J}{\\partial m}\\) and <code>c</code> the value of \\(\\frac{\\partial J}{\\partial c}\\). Assume the arrays are pandas Series.</p> \\[\\frac{\\partial J}{\\partial m} = -\\frac{2}{n} \\sum_{i=1}^{n} x_i (y_i - \\hat{y}_i)\\] \\[\\frac{\\partial J}{\\partial c} = -\\frac{2}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)\\] </li> <li> <p>We will use <code>bmi</code> as our input feature. </p> </li> <li> <p>Define the initial values for the parameters.</p> <pre><code>learningrate = 0.1\nm = []\nc = []\nJ = []\nm.append(0)\nc.append(0)\nJ.append(cost(y_train['target'], X_train['bmi'].apply(lambda x: model(x, m[-1], c[-1]))))\n</code></pre> </li> <li> <p>Define the termination conditions.</p> <pre><code>J_min = 0.01\ndel_J_min = 0.0001\nmax_iter = 10000\n</code></pre> Variable Termination condition <code>J_min</code> The algorithm terminates when the cost is less than this value. <code>del_J_min</code> The algorithm terminates when the proportion of change in cost to the current cost is less than this value. <code>max_iter</code> The algorithm terminates when the number of iteration exceeds this value. </li> <li> <p>Now develop the code to perform gradient descent. </p> <ol> <li>Check termination conditions, if any condition fulfilled, the algorithm is terminated.</li> <li>Calculate derivatives.</li> <li>Update \\(m\\) and \\(c\\); append the new values to the arrays <code>m</code> and <code>c</code>.</li> <li>Calculate \\(J\\); append the value to the array <code>J</code>. Repeat from the beginning.</li> </ol> </li> <li> <p>To provide feedback during each iteration, <code>import sys</code>, and add the following lines as the last lines in the loop.</p> <pre><code>print('.', end='')\nsys.stdout.flush()\n</code></pre> </li> <li> <p>To provide visual display for each iteration, <code>import matplotlib.pyplot as plt</code>. Add these lines before the loop.</p> <pre><code>plt.scatter(X_train['bmi'], y_train['target'], color='red')\nplt.title('Training data')\nplt.xlabel('BMI')\nline = None\n</code></pre> <p>Add the following lines as the last lines in the loop.</p> <pre><code>if line:\n  line[0].remove()\nline = plt.plot(X_train['bmi'], X_train['bmi'].apply(lambda x: model(x, m[-1], c[-1])), '-', color='green')\nplt.pause(0.001)\n</code></pre> </li> <li> <p>Outside of the loop, add the following lines to display the results.</p> <pre><code>y_train_pred = X_train['bmi'].apply(lambda x: model(x, m[-1], c[-1]))\ny_test_pred = X_test['bmi'].apply(lambda x: model(x, m[-1], c[-1]))\nprint('\\nAlgorithm terminated with')\nprint(f'  {len(J)} iterations,')\nprint(f'  m {m[-1]}')\nprint(f'  c {c[-1]}')\nprint(f'  training cost {J[-1]}')\ntestcost = cost(y_test['target'], y_test_pred)\nprint(f'  testing cost {testcost}')\n</code></pre> </li> <li> <p>Test the result on the testing data.</p> <pre><code>plt.figure()\nplt.scatter(X_test['bmi'], y_test['target'], color='red')\nplt.plot(X_test['bmi'], \\\n         X_test['bmi'].apply(lambda x: model(x, m[-1], c[-1])), \\\n         '-', color='green')\nplt.title('Testing data')\n</code></pre> </li> </ol>"},{"location":"lab4/#learning-on-linear-regression-model-using-scikit-learn","title":"Learning on linear regression model using scikit-learn","text":"<ol> <li> <p><code>scikit-learn</code> provides model and functions to perform linear regression easily.</p> <pre><code>from sklearn import linear_model\n</code></pre> </li> <li> <p>Create a linear regression model.</p> <pre><code>regrmodel = linear_model.LinearRegression()\n</code></pre> </li> <li> <p>Train the model with the training data.</p> <pre><code>regrmodel.fit(X_train[['bmi']], y_train['target'])\n</code></pre> </li> <li> <p><code>regrmodel</code> is now a trained model. To get the predicted \\(y\\) given a set of \\(x\\) values,</p> <pre><code>y_train_pred = regrmodel.predict(X_train[['bmi']])\ny_test_pred = regrmodel.predict(X_test[['bmi']])\n</code></pre> </li> <li> <p>As we are using pandas data structures, we need to convert the predicted value to Series and align the indices with the target Series.</p> <pre><code>y_train_pred = pd.Series(y_train_pred)\ny_train_pred.index = y_train.index\n\ny_test_pred = pd.Series(y_test_pred)\ny_test_pred.index = y_test.index\n</code></pre> </li> <li> <p>Display the information of the fitted model.</p> <pre><code>print('sklearn')\nprint(f'  m {regrmodel.coef_}')\nprint(f'  c {regrmodel.intercept_}')\ntraincost = cost(y_train['target'], y_train_pred)\ntestcost = cost(y_test['target'], y_test_pred)\nprint(f'  training cost: {traincost}')\nprint(f'  testing cost: {testcost}')\n</code></pre> </li> <li> <p>Display the result of prediction together with the target values.     <pre><code>plt.figure()\nplt.scatter(X_train['bmi'], y_train['target'], color='red')\nplt.plot(X_train['bmi'], y_train_pred, '-', color='green')\nplt.title('Training data (sklearn)')\nplt.xlabel('BMI')\n\nplt.figure()\nplt.scatter(X_test['bmi'], y_test['target'], color='red')\nplt.plot(X_test['bmi'], y_test_pred, '-', color='green')\nplt.title('Testing data (sklearn)')\nplt.xlabel('BMI')\n</code></pre></p> </li> </ol>"},{"location":"lab4/#multivariate-linear-regression","title":"Multivariate linear regression","text":"<ol> <li> <p>Linear regression can also be applied with multiple inputs. With \\(k\\) inputs, the linear regression equation is given as</p> \\[\\hat{y} = \\beta + m_1x_1 + m_2x_2 + \\cdots + m_kx_k\\] </li> <li> <p>With one input, the resultant function is a line; with two inputs, the resultant function is a plane; with more inputs, it's a hyperplane.</p> </li> <li> <p>Gradient descent for multivariate linear regression is performed with the same approach. </p> <ol> <li>Check termination conditions, if any condition fulfilled, the algorithm is terminated.</li> <li>Calculate derivatives.</li> <li>Update \\(m_1\\), \\(m_2\\), ..., \\(m_k\\) and \\(\\beta\\).</li> <li>Calculate \\(J\\). Repeat from the beginning.</li> </ol> </li> <li> <p>For multivariate linear regression, the least squares cost is given by     \\(\\(J = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\\)\\)</p> <p>The derivative with respect to \\(\\beta\\) \\(\\(\\frac{\\partial J}{\\partial \\beta} = -\\frac{2}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)\\)\\)</p> <p>The derivatives with respect to \\(m_j\\) \\(\\(\\frac{\\partial J}{\\partial m_j} = -\\frac{2}{n} \\sum_{i=1}^{n} x_{ji}(y_i - \\hat{y}_i)\\)\\)</p> </li> <li> <p>Using <code>scikit-learn</code> functions, multivariate linear regression can be achieved by providing the input features to the function.</p> </li> <li> <p>We will now use the <code>bmi</code> and blood pressure <code>bp</code> as the input features to predict the target. Copy the code block from the previous section and change <code>X_...[['bmi']]</code> to <code>X_...[['bmi','bp']]</code> except for the plotting part.</p> </li> <li> <p>For the graphical visualisation (plotting) part, use the following code to plot 3d graphs:</p> <pre><code>from mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(X_train['bmi'], X_train['bp'], y_train['target'], color='red')\nax.scatter(X_train['bmi'], X_train['bp'], y_train_pred, color='green')\nax.set_xlabel('BMI')\nax.set_ylabel('Blood pressure')\nax.set_title('Training data (sklearn multivariate)')\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(X_test['bmi'], X_test['bp'], y_test['target'], color='red')\nax.scatter(X_test['bmi'], X_test['bp'], y_test_pred, color='green')\nax.set_xlabel('BMI')\nax.set_ylabel('Blood pressure')\nax.set_title('Testing data (sklearn multivariate)')\n</code></pre> </li> </ol>"},{"location":"lab4/#bonus-opportunity-regression-methods-with-machine-learning","title":"Bonus Opportunity: Regression Methods with Machine Learning","text":"<p>For those interested in exploring machine learning techniques for predictive modeling, you are invited to complete the Regression Methods with Machine Learning course by MathWorks.</p> <ul> <li>Estimated Time: ~4 hours  </li> <li>Platform: Online (browser-based)  </li> <li>Outcome: Digital Certificate of Completion from MathWorks</li> </ul> <p>Action Steps: 1. Access the course here: Regression Methods with Machine Learning \u2013 MathWorks Academy 2. Work through the lessons and complete the assessments. 3. Download your Certificate of Completion. 4. Upload your certificate along with your Lab X submission on LMS.</p> <p>Bonus Recognition: - Submitting the certificate will earn you bonus recognition later in the semester. - Participation is optional and will not affect your Lab X grade.</p>"},{"location":"lab5/","title":"Lab 5: k Nearest Neighbours (KNN) (Classification Methods with ML)","text":""},{"location":"lab5/#objective","title":"Objective","text":"<ol> <li>To perform k nearest neighbours algorithm with <code>scikit-learn</code> Python library for classification and regression.</li> </ol>"},{"location":"lab5/#datasets","title":"Datasets","text":"<ol> <li> <p>The iris dataset will be used for classification, and the diabetes dataset for regression.</p> <pre><code>from sklearn import datasets\nimport pandas as pd\niris = datasets.load_iris()\niris = {\n  'attributes': pd.DataFrame(iris.data, columns=iris.feature_names),\n  'target': pd.DataFrame(iris.target, columns=['species']),\n  'targetNames': iris.target_names\n}\ndiabetes = datasets.load_diabetes()\ndiabetes = {\n  'attributes': pd.DataFrame(diabetes.data, columns=diabetes.feature_names),\n  'target': pd.DataFrame(diabetes.target, columns=['diseaseProgression'])\n}\n</code></pre> </li> <li> <p>Split the datasets into 80-20 for train-test proportion.</p> <pre><code>from sklearn.model_selection import train_test_split\nfor dt in [iris, diabetes]:\n  x_train, x_test, y_train, y_test = train_test_split(dt['attributes'], dt['target'], test_size=0.2, random_state=1)\n  dt['train'] = {\n    'attributes': x_train,\n    'target': y_train\n  }\n  dt['test'] = {\n  'attributes': x_test,\n  'target': y_test\n  }\n</code></pre> <p>Note: Be reminded that <code>random_state</code> is used to reproduce the same \"random\" split of the data whenever the function is called. To produce randomly splitted data every time the function is called, remove the <code>random_state</code> argument.</p> </li> </ol> <p>Task: How do we access the training input data for the iris dataset?</p>"},{"location":"lab5/#knn","title":"KNN","text":"<p>KNN algorithms are provided by the <code>scikit-learn</code> Python library as the class <code>sklearn.neighbors.KNeighborsClassifier</code> for classification, and <code>sklearn.neighbors.KNeighborsRegressor</code> for regression.</p>"},{"location":"lab5/#classification","title":"Classification","text":"<ol> <li> <p>Import the class for KNN classifier.</p> <pre><code>from sklearn.neighbors import KNeighborsClassifier\n</code></pre> </li> <li> <p>Instantiate an object of <code>KNeighborsClassifier</code> class with k = 5.</p> <pre><code>knc = KNeighborsClassifier(5)\n</code></pre> </li> <li> <p>Train the classifier with the training data. We will use the <code>sepal length (cm)</code> and <code>sepal width (cm)</code> (the first and second columns) as the attributes for now.</p> <pre><code>input_columns = iris['attributes'].columns[:2].tolist()\nx_train = iris['train']['attributes'][input_columns]\ny_train = iris['train']['target'].species\nknc.fit(x_train, y_train)\n</code></pre> </li> <li> <p><code>.predict</code> function is used to predict the species of the testing data.</p> <pre><code>x_test = iris['test']['attributes'][input_columns]\ny_test = iris['test']['target'].species\ny_predict = knc.predict(x_test)\n</code></pre> </li> <li> <p>Comparing the predicted value and the target value of the test data.</p> <pre><code>print(pd.DataFrame(list(zip(y_test,y_predict)), columns=['target', 'predicted']))\n</code></pre> </li> <li> <p>Calculate the accuracy of the predicted value.</p> <pre><code>print(f'Accuracy: {knc.score(x_test,y_test):.4f}')\n</code></pre> </li> <li> <p>Visualisation</p> <ol> <li> <p>Import the <code>matplotlib.pyplot</code> library and the colormaps from the <code>matplotlib</code> library.     <pre><code>import matplotlib.pyplot as plt\nfrom matplotlib import cm\nfrom matplotlib.colors import ListedColormap\n</code></pre></p> </li> <li> <p>Prepare the colormaps.     <pre><code>colormap = cm.get_cmap('tab20')\ncm_dark = ListedColormap(colormap.colors[::2])\ncm_light = ListedColormap(colormap.colors[1::2])\n</code></pre></p> </li> <li> <p>Calculate the decision boundaries.     <pre><code>import numpy as np\nx_min = iris['attributes'][input_columns[0]].min()\nx_max = iris['attributes'][input_columns[0]].max()\nx_range = x_max - x_min\nx_min = x_min - 0.1 * x_range\nx_max = x_max + 0.1 * x_range\ny_min = iris['attributes'][input_columns[1]].min()\ny_max = iris['attributes'][input_columns[1]].max()\ny_range = y_max - y_min\ny_min = y_min - 0.1 * y_range\ny_max = y_max + 0.1 * y_range\nxx, yy = np.meshgrid(np.arange(x_min, x_max, .01*x_range), \n                    np.arange(y_min, y_max, .01*y_range))\nz = knc.predict(list(zip(xx.ravel(), yy.ravel())))\nz = z.reshape(xx.shape)\n</code></pre></p> </li> <li> <p>Plot the decision boundary.     <pre><code>plt.figure(figsize=[12,8])\nplt.pcolormesh(xx, yy, z, cmap=cm_light)\n</code></pre></p> </li> <li> <p>Plot the training and testing data.     <pre><code>plt.scatter(x_train[input_columns[0]], x_train[input_columns[1]], \n            c=y_train, label='Training data', cmap=cm_dark, \n            edgecolor='black', linewidth=1, s=150)\nplt.scatter(x_test[input_columns[0]], x_test[input_columns[1]], \n            c=y_test, marker='*', label='Testing data', cmap=cm_dark, \n            edgecolor='black', linewidth=1, s=150)\nplt.xlabel(input_columns[0])\nplt.ylabel(input_columns[1])\nplt.legend()\n</code></pre></p> </li> </ol> </li> </ol> <p>Task: Create a loop to compare the accuracy of the prediction at different value of k. The comparison should be shown in a graph with k as the horizontal axis and accuracy as the vertical axis.</p>"},{"location":"lab5/#regression","title":"Regression","text":"<ol> <li> <p>Import the class for KNN regressor.     <pre><code>from sklearn.neighbors import KNeighborsRegressor\n</code></pre></p> </li> <li> <p>Instantiate an object of <code>KNeighborsRegressor</code> class with k = 5.     <pre><code>knr = KNeighborsRegressor(5)\n</code></pre></p> </li> <li> <p>Train the regressor with the training data. We will use the <code>age</code> and <code>bmi</code> as the attributes for now.     <pre><code>input_columns = ['age', 'bmi']\nx_train = diabetes['train']['attributes'][input_columns]\ny_train = diabetes['train']['target'].diseaseProgression\nknr.fit(x_train, y_train)\n</code></pre></p> </li> <li> <p><code>.predict</code> function is used to predict the disease progression of the testing data.     <pre><code>x_test = diabetes['test']['attributes'][input_columns]\ny_test = diabetes['test']['target'].diseaseProgression\ny_predict = knr.predict(x_test)\n</code></pre></p> </li> <li> <p>Comparing the predicted value and the target value of the test data.     <pre><code>print(pd.DataFrame(list(zip(y_test,y_predict)), columns=['target', 'predicted']))\n</code></pre></p> </li> <li> <p>Calculate the accuracy of the predicted value.     <pre><code>print(f'Accuracy: {knr.score(x_test,y_test):.4f}')\n</code></pre></p> </li> <li> <p>Visualisation</p> <ol> <li> <p>Import the <code>matplotlib.pyplot</code> library and the colormaps from the <code>matplotlib</code> library.     <pre><code>import matplotlib.pyplot as plt\nfrom matplotlib import cm\n</code></pre></p> </li> <li> <p>Prepare the colormaps.     <pre><code>dia_cm = cm.get_cmap('Reds')\n</code></pre></p> </li> <li> <p>Calculate the decision boundaries.     <pre><code>import numpy as np\nx_min = diabetes['attributes'][input_columns[0]].min()\nx_max = diabetes['attributes'][input_columns[0]].max()\nx_range = x_max - x_min\nx_min = x_min - 0.1 * x_range\nx_max = x_max + 0.1 * x_range\ny_min = diabetes['attributes'][input_columns[1]].min()\ny_max = diabetes['attributes'][input_columns[1]].max()\ny_range = y_max - y_min\ny_min = y_min - 0.1 * y_range\ny_max = y_max + 0.1 * y_range\nxx, yy = np.meshgrid(np.arange(x_min, x_max, .01*x_range), \n                    np.arange(y_min, y_max, .01*y_range))\nz = knr.predict(list(zip(xx.ravel(), yy.ravel())))\nz = z.reshape(xx.shape)\n</code></pre></p> </li> <li> <p>Plot the decision boundary.     <pre><code>plt.figure()\nplt.pcolormesh(xx, yy, z, cmap=dia_cm)\n</code></pre></p> </li> <li> <p>Plot the training and testing data.     <pre><code>plt.scatter(x_train[input_columns[0]], x_train[input_columns[1]], \n            c=y_train, label='Training data', cmap=dia_cm, \n            edgecolor='black', linewidth=1, s=150)\nplt.scatter(x_test[input_columns[0]], x_test[input_columns[1]], \n            c=y_test, marker='*', label='Testing data', cmap=dia_cm,\n            edgecolor='black', linewidth=1, s=150)\nplt.xlabel(input_columns[0])\nplt.ylabel(input_columns[1])\nplt.legend()\nplt.colorbar()\n</code></pre></p> </li> </ol> </li> </ol> <p>Task: Create a loop to compare the accuracy of the prediction at different value of k. The comparison should be shown in a graph with k as the horizontal axis and accuracy as the vertical axis.</p>"},{"location":"lab5/#bonus-opportunity-classification-methods-with-machine-learning","title":"Bonus Opportunity: Classification Methods with Machine Learning","text":"<p>To deepen your understanding of classification tasks in machine learning, you are encouraged to complete the Classification Methods with Machine Learning course offered by MathWorks.</p> <ul> <li>Estimated Time: ~4 hours  </li> <li>Platform: Online (browser-based)  </li> <li>Outcome: Digital Certificate of Completion from MathWorks</li> </ul> <p>Action Steps: 1. Access the course here: Classification Methods with Machine Learning \u2013 MathWorks Academy 2. Complete all course modules and activities. 3. Download your Certificate of Completion. 4. Submit the certificate along with your Lab X submission on LMS.</p> <p>Bonus Recognition: - Completing and submitting this course will earn bonus recognition later in the semester. - This activity is optional and has no impact on your Lab X grade.</p>"},{"location":"lab6/","title":"Lab 6: Decision Tree","text":""},{"location":"lab6/#objective","title":"Objective","text":"<ol> <li>To perform CART decision tree learning algorithm using the <code>scikit-learn</code> Python library.</li> </ol>"},{"location":"lab6/#datasets","title":"Datasets","text":"<p>The same iris and diabetes datasets used in Lab 7 are used here. Load the datasets and split them into 80-20 train-test proportion.</p>"},{"location":"lab6/#decision-tree","title":"Decision tree","text":"<p>Decision tree models and algorithms are provided by the <code>scikit-learn</code> as the class <code>sklearn.tree.DecisionTreeClassifier</code> for classification, and <code>sklearn.tree.DecisionTreeRegressor</code> for regression.</p>"},{"location":"lab6/#classification","title":"Classification","text":"<ol> <li> <p>Import the class for decision tree classifier.     <pre><code>from sklearn.tree import DecisionTreeClassifier\n</code></pre></p> </li> <li> <p>Instantiate an object of <code>DecisionTreeClassifier</code> class with gini impurity as the split criterion.     <pre><code>dtc = DecisionTreeClassifier(criterion='gini')\n</code></pre></p> </li> <li> <p>Train the classifier with the training data. We will use all the input attributes.     <pre><code>dtc.fit(iris['train']['attributes'], iris['train']['target'])\n</code></pre></p> </li> <li> <p><code>.predict</code> function is used to predict the species of the testing data.     <pre><code>predicts = dtc.predict(iris['test']['attributes'])\n</code></pre></p> </li> <li> <p>Comparing the predicted value and the target value of the test data.     <pre><code>print(pd.DataFrame(list(zip(iris['test']['target'].species,predicts)), columns=['target', 'predicted']))\n</code></pre></p> </li> <li> <p>Calculate the accuracy of the predicted value.     <pre><code>accuracy = dtc.score(iris['test']['attributes'],iris['test']['target'].species)\nprint(f'Accuracy: {accuracy:.4f}')\n</code></pre></p> </li> <li> <p>Decision tree visualisation</p> <ol> <li> <p>Import the <code>matplotlib.pyplot</code> library and the function to visualise the tree.     <pre><code>import matplotlib.pyplot as plt\nfrom sklearn.tree import plot_tree\n</code></pre></p> </li> <li> <p>Visualise the decision tree model.     <pre><code>plt.figure(figsize=[10,10])\ntree = plot_tree(dtc, feature_names=iris['attributes'].columns.tolist(), \n                 class_names=iris['targetNames'], filled=True, rounded=True)\n</code></pre></p> </li> </ol> </li> </ol> <p>The maximum depth of a decision tree can be defined by adding the <code>max_depth=...</code> argument to the <code>DecisionTreeClassifier(...)</code> object instantiation. To allow unlimited maximum depth, pass <code>max_depth=None</code>.</p> <p>Task: Create a loop to compare the accuracy of the prediction with different maximum depths. Use 1, 2, 3, 5, 7, and 20 as the maximum depths. In every iteration, you should calculate both the accuracy on the training data and the accuracy on the testing data. The comparison should be shown in a graph with <code>max_depth</code> as the horizontal axis and accuracy as the vertical axis. Two lines should be displayed on the graph with one line for training accuracy and the other testing accuracy.</p>"},{"location":"lab6/#visualisation-of-decision-surface","title":"Visualisation of decision surface","text":"<p>This section explains the method to visualise a decision tree on a graph. To do so we will focus on using two input attributes, sepal length and sepal width, i.e. the first two columns.</p> <ol> <li> <p>Instantiate the classifier without defining the maximum depth and train the model.     <pre><code>dtc = DecisionTreeClassifier()\ninput_cols = iris['train']['attributes'].columns[:2].tolist()\ndtc.fit(iris['train']['attributes'][input_cols], iris['train']['target'].species)\n</code></pre></p> </li> <li> <p>Plot the decision tree.     <pre><code>plt.figure(figsize=[50,50])\nplot_tree(dtc, feature_names=input_cols, \n          class_names=iris['targetNames'], filled=True, rounded=True)\nplt.savefig('classificationDecisionTreeWithNoMaxDepth.png')\n</code></pre></p> </li> <li> <p>Prepare the colormaps.     <pre><code>from matplotlib import cm\nfrom matplotlib.colors import ListedColormap\ncolormap = cm.get_cmap('tab20')\ncm_dark = ListedColormap(colormap.colors[::2])\ncm_light = ListedColormap(colormap.colors[1::2])\n</code></pre></p> </li> <li> <p>Calculating the decision surface.     <pre><code>import numpy as np\nx_min = iris['attributes'][input_cols[0]].min()\nx_max = iris['attributes'][input_cols[0]].max()\nx_range = x_max - x_min\nx_min = x_min - 0.1 * x_range\nx_max = x_max + 0.1 * x_range\ny_min = iris['attributes'][input_cols[1]].min()\ny_max = iris['attributes'][input_cols[1]].max()\ny_range = y_max - y_min\ny_min = y_min - 0.1 * y_range\ny_max = y_max + 0.1 * y_range\nxx, yy = np.meshgrid(np.arange(x_min, x_max, .01*x_range), \n                    np.arange(y_min, y_max, .01*y_range))\nz = dtc.predict(list(zip(xx.ravel(), yy.ravel())))\nz = z.reshape(xx.shape)\n</code></pre></p> </li> <li> <p>Plot the decision surface.     <pre><code>plt.figure()\nplt.pcolormesh(xx, yy, z, cmap=cm_light)\n</code></pre></p> </li> <li> <p>Plot the training and testing data.     <pre><code>plt.scatter(iris['train']['attributes'][input_cols[0]],   \n            iris['train']['attributes'][input_cols[1]], \n            c=iris['train']['target'].species, cmap=cm_dark, s=200,\n            label='Training data', edgecolor='black', linewidth=1)\nplt.scatter(iris['test']['attributes'][input_cols[0]], \n            iris['test']['attributes'][input_cols[1]], \n            c=iris['test']['target'].species, cmap=cm_dark, s=200,\n            label='Testing data', edgecolor='black', linewidth=1,\n            marker='*')\ntrain_acc = dtc.score(iris['train']['attributes'][input_cols], \n                      iris['train']['target'].species)\ntest_acc = dtc.score(iris['test']['attributes'][input_cols], \n                    iris['test']['target'].species)\nplt.title(f'training: {train_acc:.3f}, testing: {test_acc:.3f}')\nplt.xlabel(input_cols[0])\nplt.ylabel(input_cols[1])\nplt.legend()\n</code></pre></p> </li> </ol> <p>You may not be able to see anything on one of the graph of the decision tree because the figure size is set to be larger than the screen size. However, the tree is saved to a png file in the same folder as your code.</p>"},{"location":"lab6/#overfitting","title":"Overfitting","text":"<p>Now, instantiate a decision tree classifier of <code>max_depth=3</code> and train it with the two input attributes used in the previous section, sepal length and sepal width.</p> <p>Plot the decision surface for this classifier after the training. Compare the decision surface, training accuracy, and testing accuracy between this model and the model in the previous section. </p> <p>The previous model shows a situation of overfitting. Though the training accuracy of this model is lower than that of the previous one, the testing accuracy is higher than the previous one. That shows a higher level of generalisation.</p>"},{"location":"lab6/#regression","title":"Regression","text":"<ol> <li> <p>Import the class for decision tree regressor.     <pre><code>from sklearn.tree import DecisionTreeRegressor\n</code></pre></p> </li> <li> <p>Instantiate an object of <code>DecisionTreeRegressor</code> class.     <pre><code>dtr = DecisionTreeRegressor()\n</code></pre></p> </li> <li> <p>Train the classifier with the training data. We will use all the input attributes.     <pre><code>dtr.fit(diabetes['train']['attributes'], diabetes['train']['target'])\n</code></pre></p> </li> <li> <p><code>.predict</code> function is used to predict the disease progression of the testing data.     <pre><code>predicts = dtr.predict(diabetes['test']['attributes'])\n</code></pre></p> </li> <li> <p>Comparing the predicted value and the target value of the test data.     <pre><code>print(pd.DataFrame(list(zip(diabetes['test']['target'].diseaseProgression,predicts)), \n                  columns=['target', 'predicted']))\n</code></pre></p> </li> <li> <p>Calculate the accuracy of the predicted value.     <pre><code>accuracy = dtr.score(diabetes['test']['attributes'],\n                    diabetes['test']['target'].diseaseProgression)\nprint(f'Accuracy: {accuracy:.4f}')\n</code></pre></p> </li> <li> <p>Decision tree visualisation</p> <ol> <li> <p>Import the <code>matplotlib.pyplot</code> library and the function to visualise the tree.     <pre><code>import matplotlib.pyplot as plt\nfrom sklearn.tree import plot_tree\n</code></pre></p> </li> <li> <p>Visualise the decision tree model.     <pre><code>plt.figure(figsize=[10,10])\ntree = plot_tree(dtr, feature_names=diabetes['attributes'].columns.tolist(), \n                filled=True, rounded=True)\n</code></pre></p> </li> </ol> </li> </ol> <p>The maximum depth of a decision tree can be defined by adding the <code>max_depth=...</code> argument to the <code>DecisionTreeRegressor(...)</code> object instantiation. To allow unlimited maximum depth, pass <code>max_depth=None</code>.</p> <p>Task: Create a loop to compare the accuracy of the prediction with different maximum depths. Use 1, 2, 3, 5, 7, and 20 as the maximum depths. In every iteration, you should calculate both the accuracy on the training data and the accuracy on the testing data. The comparison should be shown in a graph with <code>max_depth</code> as the horizontal axis and accuracy as the vertical axis. Two lines should be displayed on the graph with one line for training accuracy and the other testing accuracy.</p>"},{"location":"lab6/#visualisation-of-decision-surface_1","title":"Visualisation of decision surface","text":"<p>This section explains the method to visualise a decision tree on a graph. To do so we will focus on using two input attributes, <code>age</code> and <code>bmi</code>.</p> <ol> <li> <p>Instantiate the classifier without defining the maximum depth and train the model.     <pre><code>dtr = DecisionTreeRegressor()\ninput_cols = ['age', 'bmi']\ndtr.fit(diabetes['train']['attributes'][input_cols], \n        diabetes['train']['target'].diseaseProgression)\n</code></pre></p> </li> <li> <p>Plot the decision tree.     <pre><code>plt.figure(figsize=[50,50])\nplot_tree(dtr, feature_names=input_cols, filled=True, rounded=True)\nplt.savefig('regressionDecisionTreeWithNoMaxDepth.png')\n</code></pre></p> </li> <li> <p>Prepare the colormaps.     <pre><code>from matplotlib import cm\ndia_cm = cm.get_cmap('Reds')\n</code></pre></p> </li> <li> <p>Create the decision surface.     <pre><code>import numpy as np\nx_min = diabetes['attributes'][input_cols[0]].min()\nx_max = diabetes['attributes'][input_cols[0]].max()\nx_range = x_max - x_min\nx_min = x_min - 0.1 * x_range\nx_max = x_max + 0.1 * x_range\ny_min = diabetes['attributes'][input_cols[1]].min()\ny_max = diabetes['attributes'][input_cols[1]].max()\ny_range = y_max - y_min\ny_min = y_min - 0.1 * y_range\ny_max = y_max + 0.1 * y_range\nxx, yy = np.meshgrid(np.arange(x_min, x_max, .01*x_range), \n                    np.arange(y_min, y_max, .01*y_range))\nz = dtr.predict(list(zip(xx.ravel(), yy.ravel())))\nz = z.reshape(xx.shape)\n</code></pre></p> </li> <li> <p>Plot the decision surface     <pre><code>plt.figure()\nplt.pcolormesh(xx, yy, z, cmap=dia_cm)\n</code></pre></p> </li> <li> <p>Plot the training and testing data.     <pre><code>plt.scatter(diabetes['train']['attributes'][input_cols[0]],          \n            diabetes['train']['attributes'][input_cols[1]], \n            c=diabetes['train']['target'].diseaseProgression, \n            label='Training data', cmap=dia_cm, \n            edgecolor='black', linewidth=1, s=150)\nplt.scatter(diabetes['test']['attributes'][input_cols[0]],   \n            diabetes['test']['attributes'][input_cols[1]], \n            c=diabetes['test']['target'].diseaseProgression, marker='*', \n            label='Testing data', cmap=dia_cm, \n            edgecolor='black', linewidth=1, s=150)\nplt.xlabel(input_cols[0])\nplt.ylabel(input_cols[1])\nplt.legend()\nplt.colorbar()\n</code></pre></p> </li> </ol>"},{"location":"lab6/#overfitting_1","title":"Overfitting","text":"<p>Now, instantiate a decision tree regressor of <code>max_depth=3</code> and train it with the two input attributes used in the previous section, <code>age</code> and <code>bmi</code>.</p> <p>Plot the decision surface for this regressor after the training. Compare the decision surface, training accuracy, and testing accuracy between this model and the model in the previous section. </p> <p>The previous model shows a situation of overfitting. Though the training accuracy of this model is lower than that of the previous one, the testing accuracy is higher than the previous one. That shows a higher level of generalisation.</p>"},{"location":"lab7/","title":"Lab 7: Clustering (Cluster Analysis with ML)","text":""},{"location":"lab7/#objective","title":"Objective","text":"<ol> <li> <p>To implement k-means clustering algorithm using basic Python.</p> </li> <li> <p>To perform k-means clustering algorithm with <code>scikit-learn</code> Python library.</p> </li> </ol>"},{"location":"lab7/#note","title":"Note","text":"<ol> <li>Suggestion: use <code>numpy</code> library to simplify the operation.</li> </ol>"},{"location":"lab7/#k-means-clustering-using-basic-python","title":"k-means clustering using basic Python","text":"<ol> <li> <p>The following code structure will be used for this section:</p> <pre><code># import libraries\n...\n\n# functions\n## function to take input of data and number of clusters, return centroids and other data\ndef get_random_centroids(data_points, n_centroids=2):\n  pass\n\n## function to group data according to centroids\ndef group_to_centroids(data_points, centroids):\n  pass\n\n## function to calculate centroids from grouped data\ndef find_centroids(data_points, groups):\n  pass\n\n# generate dataset\n...\n\n# identify initial centroids\n...\n\n# repeat until centroids stabilise\nwhile ...:\n  ## group data to centroids\n  ...\n  ## update centroids\n  ...\n\nprint('terminated')\n</code></pre> </li> </ol>"},{"location":"lab7/#dataset","title":"Dataset","text":"<ol> <li> <p>The code in this subsection will populate     <pre><code># generate dataset\n...\n</code></pre></p> </li> <li> <p>We will create a dataset of 200 with 2 input features and 4 clusters.</p> <pre><code>from sklearn.datasets import make_blobs\ndata = make_blobs(n_samples=200, n_features=2, centers=4, cluster_std=1.6, random_state=50)\n</code></pre> </li> <li> <p><code>data</code> is an array of two elements. First element contains the data points, and second element contains the index of the cluster.</p> <pre><code>points = data[0]\n</code></pre> </li> <li> <p>Plot the data on a scatter graph with colour representing the cluster of the points.</p> <pre><code>import matplotlib.pyplot as plt\nplt.scatter(data[0][:,0], data[0][:,1], c=data[1])\n</code></pre> </li> </ol>"},{"location":"lab7/#initialisation","title":"Initialisation","text":"<ol> <li> <p>The initialisation for k-means clustering algorithm involves the identification of k random points from the dataset.</p> </li> <li> <p>In the <code>get_random_centroids</code> function, pass the dataset and the number of centroids to be identified as the input arguments. </p> </li> <li> <p>In the body of the function, randomly identify the centroids from the dataset.</p> </li> <li> <p>The function should return two outputs, the randomly identified centroids and the dataset without the centroids.</p> </li> <li> <p>Update your code with the following snippet:     <pre><code># identify initial centroids\ncentroids, others = get_random_centroids(points, 4)\n</code></pre></p> </li> </ol>"},{"location":"lab7/#cluster-the-points","title":"Cluster the points","text":"<ol> <li> <p>The <code>group_to_centroids</code> function takes two inputs, the data points to be clustered and the centroids to cluster to.</p> </li> <li> <p>In the <code>group_to_centroids</code> function, calculate the distance of every point from each centroid.</p> </li> <li> <p>Then identify the centroid each point should be clustered to.</p> </li> <li> <p>The function should return the index of the centroid each point is clustered to. </p> </li> <li> <p>Update your code with the following snippet:     <pre><code>## group data to centroids\ngroups = group_to_centroids(others, centroids)\n</code></pre></p> </li> </ol>"},{"location":"lab7/#update-the-centroids","title":"Update the centroids","text":"<ol> <li> <p>The <code>find_centroids</code> function takes two inputs, the data points and the index of the centroid each point is clustered to (i.e. output of <code>group_to_centroids</code>)</p> </li> <li> <p>The <code>find_centroids</code> function calculates and returns the new set of centroids based on the clustered data points.</p> </li> <li> <p>Update your code with the following snippet:     <pre><code>## update centroids\ncentroids = find_centroids(others, groups)\n</code></pre></p> </li> </ol>"},{"location":"lab7/#termination-condition","title":"Termination condition","text":"<ol> <li>The clustering algorithm should terminate when the centroids stabilise, i.e. do not change much.</li> </ol>"},{"location":"lab7/#visualisation","title":"Visualisation","text":"<ol> <li> <p>Update your code according to the following sample to visualise the centroids and clusters at every iteration.     <pre><code>fig = plt.figure()\nax = fig.add_subplot(111)\n# repeat until centroids stabilise\nwhile ...:\n  ## group data to centroids\n  groups = group_to_centroids(others, centroids)\n\n  ## update centroids\n  centroids = find_centroids(others, groups)\n\n  ## visualise current clusters and centroids\n  ax.clear()\n  ax.scatter(others[:,0], others[:,1], c=groups)\n  ax.scatter(centroids[:,0], centroids[:,1], marker='*', c='k')\n\n  ## pause for one second\n  plt.pause(1)\n</code></pre></p> </li> <li> <p>Are Figure 1 (originally generated clusters) and Figure 2 (calculated clusters) identical?</p> </li> </ol>"},{"location":"lab7/#k-means-clustering-using-scikit-learn-python-library","title":"k-means clustering using <code>scikit-learn</code> Python library","text":"<ol> <li> <p>The following code structure will be used for this section:</p> <pre><code># import libraries\n...\n\n# generate dataset\n...\n\n# initialise the k-means model\n...\n\n# train the k-means model\n...\n\n# identify the cluster of each point\n...\n\n# visualise the result\n...\n</code></pre> </li> </ol>"},{"location":"lab7/#dataset_1","title":"Dataset","text":"<ol> <li>We will use the exact same data generation as the previous section.</li> </ol>"},{"location":"lab7/#k-means-model","title":"k-means model","text":"<ol> <li> <p>The k-means model is provided by <code>sklearn.cluster.KMeans</code>.     <pre><code>from sklearn.cluster import KMeans\n</code></pre></p> </li> <li> <p>Initialise the k-means model with 4 clusters using <code>KMeans</code>. (Check the documentation to identify the usage of <code>KMeans</code>)</p> </li> </ol>"},{"location":"lab7/#training","title":"Training","text":"<ol> <li> <p>The k-means model initialised need to be trained with the data.</p> </li> <li> <p>The training is executed using <code>sklearn.cluster.KMeans.fit</code>. (Identify the input argument(s))     <pre><code>kmeans.fit(...)\n</code></pre></p> </li> </ol>"},{"location":"lab7/#cluster-the-points_1","title":"Cluster the points","text":"<ol> <li>The trained model can be used to cluster the points to their respective cluster using <code>sklearn.cluster.KMeans.fit_predict</code>. (Identify the input argument(s))     <pre><code>y_km = kmeans.fit_predict(...)\n</code></pre></li> </ol>"},{"location":"lab7/#visualisation_1","title":"Visualisation","text":"<ol> <li>The visualisation of the result can be achieved with the following code:     <pre><code>plt.figure()\nplt.scatter(points[:,0], points[:,1], c=y_km)\nplt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], c='k')\n</code></pre></li> </ol> <p>Task: Compare the results of the two methods, are they similar?</p>"},{"location":"lab7/#bonus-opportunity-cluster-analysis-with-machine-learning","title":"Bonus Opportunity: Cluster Analysis with Machine Learning","text":"<p>To complement your learning of unsupervised techniques, you are encouraged to complete the Cluster Analysis with Machine Learning course by MathWorks.</p> <ul> <li>Estimated Time: ~3 hours  </li> <li>Platform: Online (browser-based)  </li> <li>Outcome: Digital Certificate of Completion from MathWorks</li> </ul> <p>Action Steps: 1. Access the course here: Cluster Analysis with Machine Learning \u2013 MathWorks Academy 2. Complete all modules and quizzes. 3. Download your Certificate of Completion. 4. Upload your certificate together with your Lab X submission on LMS.</p> <p>Bonus Recognition: - Students who complete and submit the certificate will receive bonus recognition in class. - This activity is optional and will not impact your Lab X grade.</p>"}]}